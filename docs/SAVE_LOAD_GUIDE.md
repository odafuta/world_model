# Save/Loadæ©Ÿèƒ½ å®Œå…¨å®Ÿè£…ã‚¬ã‚¤ãƒ‰

## âœ… å®Ÿè£…å®Œäº†å†…å®¹

### 1. ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®æœ€é©åŒ–

**ä¿®æ­£å‰ï¼ˆå†—é•·ï¼‰:**
```python
from matwm_implementation import (
    MATWMConfig,
    PrioritizedReplayBuffer,  # âŒ é–“æ¥ä½¿ç”¨ã®ã¿
    Encoder, Decoder,         # âŒ é–“æ¥ä½¿ç”¨ã®ã¿
    DynamicsModel,            # âŒ é–“æ¥ä½¿ç”¨ã®ã¿
    ...
)
```

**ä¿®æ­£å¾Œï¼ˆæœ€å°é™ï¼‰:**
```python
from matwm_implementation import MATWMConfig  # âœ… ç›´æ¥ä½¿ç”¨
# ãã®ä»–ã¯MATWMAgentå†…éƒ¨ã§ä½¿ç”¨
```

### 2. Saveæ©Ÿèƒ½ã®å®Œå…¨å®Ÿè£…

#### è¨“ç·´ä¸­ã®è‡ªå‹•ä¿å­˜
- **é »åº¦**: 5,000ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ï¼ˆ`config.save_interval`ï¼‰
- **ä¿å­˜å†…å®¹**:
  - âœ… å…±æœ‰World Model
  - âœ… å…±æœ‰World Model Optimizer
  - âœ… å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®Actor/Critic
  - âœ… å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®Optimizer
  - âœ… Episode Rewardså±¥æ­´
  - âœ… Training Metricså±¥æ­´
  - âœ… ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°

#### ä¿å­˜å ´æ‰€
```
results/matwm_2026_01_18_15_30_00/
â”œâ”€â”€ checkpoint_5000/
â”‚   â”œâ”€â”€ full_checkpoint.pt      # å®Œå…¨ãªè¨“ç·´çŠ¶æ…‹
â”‚   â”œâ”€â”€ adversary_0.pt          # å€‹åˆ¥ä¿å­˜ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
â”‚   â”œâ”€â”€ adversary_1.pt
â”‚   â”œâ”€â”€ adversary_2.pt
â”‚   â””â”€â”€ agent_0.pt
â”œâ”€â”€ checkpoint_10000/
â”‚   â””â”€â”€ ...
â””â”€â”€ final/
    â””â”€â”€ full_checkpoint.pt      # æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
```

### 3. Loadæ©Ÿèƒ½ã®å®Œå…¨å®Ÿè£…

#### ä½¿ç”¨æ–¹æ³•

**æ–°è¦è¨“ç·´:**
```python
agents, episode_rewards, training_metrics = train_matwm(config)
```

**è¨“ç·´å†é–‹:**
```python
checkpoint_path = 'results/.../checkpoint_25000/full_checkpoint.pt'
agents, episode_rewards, training_metrics = train_matwm(
    config,
    resume_from=checkpoint_path
)
```

#### å†é–‹æ™‚ã«å¾©å…ƒã•ã‚Œã‚‹ã‚‚ã®
1. âœ… World Model ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
2. âœ… World Model OptimizerçŠ¶æ…‹ï¼ˆå­¦ç¿’ç‡ã€momentumç­‰ï¼‰
3. âœ… å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®Actor/Critic ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
4. âœ… å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®OptimizerçŠ¶æ…‹
5. âœ… Episode Rewardså±¥æ­´ï¼ˆå¯è¦–åŒ–ã®ç¶™ç¶šï¼‰
6. âœ… Training Metricså±¥æ­´ï¼ˆå­¦ç¿’æ›²ç·šã®ç¶™ç¶šï¼‰
7. âœ… è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼ˆæ­£ç¢ºãªå†é–‹ä½ç½®ï¼‰

---

## ğŸ“Š ä½¿ç”¨ä¾‹

### ä¾‹1: é•·æ™‚é–“è¨“ç·´ï¼ˆåˆ†å‰²å®Ÿè¡Œï¼‰

```python
# Day 1: 25,000ã‚¹ãƒ†ãƒƒãƒ—è¨“ç·´
config = MATWMConfig(total_steps=25000)
agents, rewards, metrics = train_matwm(config)
# â†’ checkpoint_25000/full_checkpoint.pt ã«ä¿å­˜

# Day 2: æ®‹ã‚Š25,000ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç¶šè¡Œï¼ˆåˆè¨ˆ50,000ï¼‰
config = MATWMConfig(total_steps=50000)  # ç·åˆç›®æ¨™
agents, rewards, metrics = train_matwm(
    config,
    resume_from='results/.../checkpoint_25000/full_checkpoint.pt'
)
# â†’ 25,000ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰å†é–‹ã€50,000ã¾ã§è¨“ç·´
```

### ä¾‹2: äº‹æ•…ã‹ã‚‰ã®å›å¾©

```python
# è¨“ç·´ä¸­ã«ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ãŸå ´åˆ
config = MATWMConfig(total_steps=50000)

# æœ€å¾Œã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹
agents, rewards, metrics = train_matwm(
    config,
    resume_from='results/.../checkpoint_40000/full_checkpoint.pt'
)
# â†’ 40,000ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰å†é–‹
```

### ä¾‹3: ãƒã‚¤ãƒ‘ãƒ©èª¿æ•´å¾Œã®ç¶™ç¶š

```python
# ã¾ãšãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¨“ç·´
config = MATWMConfig(total_steps=10000)
agents, rewards, metrics = train_matwm(config)

# å­¦ç¿’ç‡ã‚’èª¿æ•´ã—ã¦ç¶™ç¶š
config_tuned = MATWMConfig(
    total_steps=50000,
    agent_learning_rate=1e-4  # å¤‰æ›´
)
agents, rewards, metrics = train_matwm(
    config_tuned,
    resume_from='results/.../checkpoint_10000/full_checkpoint.pt'
)
```

---

## ğŸ” å®Ÿè£…ã®è©³ç´°

### save_full_checkpoint() ã®å†…éƒ¨æ§‹é€ 

```python
checkpoint = {
    'global_step': 25000,  # ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—
    'shared_world_model': state_dict,  # WMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    'shared_wm_optimizer': state_dict,  # WM Optimizer
    'episode_rewards': {
        'adversary_0': [10.5, 12.3, ...],  # å…¨å±¥æ­´
        'adversary_1': [...],
        ...
    },
    'training_metrics': {
        'shared_wm_total_loss': [0.52, 0.48, ...],
        'adversary_0_actor_loss': [...],
        ...
    },
    'agents': {
        'adversary_0': {
            'actor': state_dict,
            'critic': state_dict,
            'actor_optimizer': state_dict,
            'critic_optimizer': state_dict,
        },
        ...
    }
}
```

### load_full_checkpoint() ã®å¾©å…ƒãƒ—ãƒ­ã‚»ã‚¹

1. **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿**
   ```python
   checkpoint = torch.load(path, map_location=device)
   ```

2. **World Modelå¾©å…ƒ**
   ```python
   shared_world_model.load_state_dict(checkpoint['shared_world_model'])
   shared_wm_optimizer.load_state_dict(checkpoint['shared_wm_optimizer'])
   ```

3. **å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¾©å…ƒ**
   ```python
   for name, agent in agents.items():
       agent.actor.load_state_dict(checkpoint['agents'][name]['actor'])
       agent.critic.load_state_dict(checkpoint['agents'][name]['critic'])
       agent.actor_optimizer.load_state_dict(...)
       agent.critic_optimizer.load_state_dict(...)
   ```

4. **ãƒ¡ãƒˆãƒªã‚¯ã‚¹å¾©å…ƒ**
   ```python
   episode_rewards = checkpoint['episode_rewards']
   training_metrics = checkpoint['training_metrics']
   start_step = checkpoint['global_step']
   ```

---

## ğŸ¯ è«–æ–‡ã¨ã®å¯¾å¿œ

### MATWMè«–æ–‡ã®è¨“ç·´è¨­å®š

| ç’°å¢ƒ | Total Steps | Checkpointé–“éš”ï¼ˆæ¨å¥¨ï¼‰ |
|------|------------|---------------------|
| Simple Tag (4 agents) | 50K | 5K (10å›ä¿å­˜) |
| SMAC Easy Maps | 50K | 5K |
| SMAC Hard Maps | 200K | 10K (20å›ä¿å­˜) |
| Image-based | 50K | 5K |

### æœ¬å®Ÿè£…ã®è¨­å®š

```python
config = MATWMConfig(
    total_steps=50000,     # è«–æ–‡æº–æ‹ 
    save_interval=5000,    # 10å›ä¿å­˜
)
```

**ä¿å­˜é »åº¦ã®æ¨å¥¨:**
- âœ… 5,000ã‚¹ãƒ†ãƒƒãƒ—: é©åº¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
- âš ï¸ 1,000ã‚¹ãƒ†ãƒƒãƒ—: é »ç¹ã™ãï¼ˆãƒ‡ã‚£ã‚¹ã‚¯I/Oéå¤šï¼‰
- âŒ 10,000ã‚¹ãƒ†ãƒƒãƒ—: ç²—ã™ãï¼ˆã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ™‚ã®æå¤±å¤§ï¼‰

---

## ğŸ’¾ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡

### 1ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ã‚µã‚¤ã‚ºï¼ˆæ¦‚ç®—ï¼‰

```
checkpoint_5000/
â”œâ”€â”€ full_checkpoint.pt      # ~50-100MBï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰
â”‚   â”œâ”€â”€ World Model         # ~20-40MB
â”‚   â”œâ”€â”€ Optimizers          # ~20-40MB
â”‚   â”œâ”€â”€ Agents (4)          # ~10-20MB
â”‚   â””â”€â”€ Metrics             # ~1-5MB
â”œâ”€â”€ adversary_0.pt          # ~5MBï¼ˆå€‹åˆ¥ï¼‰
â”œâ”€â”€ adversary_1.pt          # ~5MB
â”œâ”€â”€ adversary_2.pt          # ~5MB
â””â”€â”€ agent_0.pt              # ~5MB
Total: ~70-120MB/checkpoint
```

### å®Œå…¨è¨“ç·´ã§ã®ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡

**50K steps, 5Ké–“éš”:**
- Checkpoints: 10å€‹
- åˆè¨ˆ: ~700MB - 1.2GB

---

## ğŸš€ ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. å®šæœŸçš„ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
```python
# é‡è¦ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
import shutil
shutil.copy(
    'results/.../checkpoint_25000/full_checkpoint.pt',
    'backups/milestone_25k.pt'
)
```

### 2. å¤ã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®å‰Šé™¤
```python
# æœ€æ–°3ã¤ã ã‘æ®‹ã™ï¼ˆãƒ‡ã‚£ã‚¹ã‚¯ç¯€ç´„ï¼‰
# è¨“ç·´é–¢æ•°ã«è¿½åŠ å¯èƒ½
```

### 3. ã‚¯ãƒ©ã‚¦ãƒ‰ã¸ã®è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
```python
# Google Drive, AWS S3ç­‰ã¸è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
# è¨“ç·´é–¢æ•°ã®saveå¾Œã«è¿½åŠ 
```

---

## âœ… ã¾ã¨ã‚

| æ©Ÿèƒ½ | å®Ÿè£…çŠ¶æ³ | ä½¿ç”¨é »åº¦ |
|------|----------|----------|
| **è‡ªå‹•ä¿å­˜** | âœ… å®Œå…¨å®Ÿè£… | 5,000ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ |
| **è¨“ç·´å†é–‹** | âœ… å®Œå…¨å®Ÿè£… | å¿…è¦æ™‚ã«æ‰‹å‹• |
| **ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜** | âœ… å®Œå…¨å®Ÿè£… | è‡ªå‹• |
| **æœ€çµ‚ä¿å­˜** | âœ… å®Œå…¨å®Ÿè£… | è¨“ç·´çµ‚äº†æ™‚ |

**ã“ã‚Œã§è«–æ–‡æº–æ‹ ã®å®Œå…¨ãªSave/Loadæ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¾ã—ãŸï¼** ğŸ‰

é•·æ™‚é–“è¨“ç·´ã§ã‚‚å®‰å¿ƒã—ã¦ä¸­æ–­ãƒ»å†é–‹ã§ãã¾ã™ã€‚
